{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Process of Deep Learning in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as dutils\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = '~/Datasets/'\n",
    "data_root = '/data/ssd/torchvision/'    \n",
    "batch_size = 32\n",
    "val_batch_size = 128\n",
    "\n",
    "try:\n",
    "    username = os.getlogin()\n",
    "except OSError:\n",
    "    username = os.environ.get(\"USER\")\n",
    "\n",
    "gpu_no = hash(username) % 4\n",
    "\n",
    "device = torch.device(f'cuda:{gpu_no}' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. View storage usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading data\n",
    "\n",
    "References:\n",
    "\n",
    "`torchvision.datasets`: https://pytorch.org/vision/stable/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(data_root, train=True, download=True)\n",
    "print(trainset)\n",
    "print('-----')\n",
    "print(trainset.data.shape, type(trainset.data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalization\n",
    "\n",
    "References:\n",
    "\n",
    "`Tensor.float`: https://pytorch.org/docs/stable/generated/torch.Tensor.float.html#torch.Tensor.float\n",
    "\n",
    "`torch.mean`: https://pytorch.org/docs/stable/generated/torch.mean.html\n",
    "\n",
    "`torch.std`: https://pytorch.org/docs/stable/generated/torch.std.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = trainset.data.mean() / 255.       # error\n",
    "mean = trainset.data.float().mean() / 255.\n",
    "std = trainset.data.float().std(unbiased=True) / 255.\n",
    "\n",
    "print(f'mean = {mean} \\nstd  = {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Transforms\n",
    "\n",
    "References:\n",
    "\n",
    "`torchvision.transforms`: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                   # .div_(255)\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.Normalize(mean, std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create dataloaders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(data_root, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(data_root, train=False, transform=transform)\n",
    "train_set, val_set = dutils.random_split(train_set, [50000, 10000])\n",
    "\n",
    "train_loader = dutils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = dutils.DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n",
    "test_loader = dutils.DataLoader(test_set, batch_size=val_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Show sample images\n",
    "\n",
    "References:\n",
    "\n",
    "`matplotlib.pyplot`: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img * std + mean\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg.transpose((1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "input, target = data_iter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(input, nrow=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Introduction to CNN\n",
    "\n",
    "See the tutorials in [cs231n](https://cs231n.github.io/convolutional-networks/) and [theano](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html).\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_output_size(in_size, kernel_size, stride=1, padding=0, dilation=1):\n",
    "    return math.floor((in_size + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()         # Don't forget\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 8, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(8, 16, 3),  # nn.LazyConv2d(16, 3),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 8, 3),  # nn.LazyConv2d(8, 3),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8*2*2, 32), # nn.LazyLinear(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = self.classifier(x)\n",
    "        return x            # outputs logits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(16, 1, 28, 28)   # (B, C, H, W)\n",
    "y = model(x.to(device))         # (B, L)\n",
    "\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss function\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "https://github.com/Jaewan-Yun/optimizer-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([\n",
    "    {'params': model.feature.parameters()},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "], lr=1e-2, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _val(dataloader, **kwargs):\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader, **kwargs) as batches:\n",
    "            for batch in batches:\n",
    "                input, target = batch\n",
    "                input, target = input.to(device), target.to(device)\n",
    "\n",
    "                output = model(input)\n",
    "                _, prediction = torch.max(output, 1)\n",
    "\n",
    "                total += target.size(0)\n",
    "                correct += int((prediction == target).sum())\n",
    "\n",
    "    accuracy = correct / total        \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def validate():\n",
    "    return _val(val_loader, desc='Validating', leave=False)\n",
    "\n",
    "def test():\n",
    "    return _val(test_loader, desc='Testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    model.train()   # set the model in training mode\n",
    "    \n",
    "\n",
    "    with tqdm(range(1, num_epochs+1), desc='Training') as epochs:\n",
    "        for epoch in epochs:\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            with tqdm(train_loader, desc=f'Epoch {epoch}') as batches:\n",
    "                loss_step = 0.0\n",
    "                \n",
    "                for step, batch in enumerate(batches, 1):\n",
    "                    input, target = batch\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()    # you can also accumulate gradients of multiple steps as learning from a larger batch\n",
    "                    \n",
    "                    output = model(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()     # calculate gradients\n",
    "                    \n",
    "                    optimizer.step()        # performs gradient descent\n",
    "                    \n",
    "                    loss_step += float(loss)\n",
    "                    if step % 50 == 0:\n",
    "                        batches.set_postfix({\n",
    "                            'steps': step,\n",
    "                            'loss_step': f'{loss_step/50:.3f}'\n",
    "                        })\n",
    "                        loss_step = 0\n",
    "                        \n",
    "                    train_loss += float(loss)\n",
    "                \n",
    "                val_acc = validate()\n",
    "                epochs.set_postfix({\n",
    "                    'loss': f'{train_loss/step:.3f}',\n",
    "                    'val_acc': f'{val_acc:.3f}'\n",
    "                })\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test()\n",
    "print(f'Test accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Shutdown\n",
    "\n",
    "From Jupyter home, click `Running`, shutdown this kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
